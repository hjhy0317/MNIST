{"cells":[{"cell_type":"markdown","metadata":{"id":"6ZPsdMOZNHb4"},"source":["필요한 라이브러리 import"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3111,"status":"ok","timestamp":1708653321586,"user":{"displayName":"Chaewon Lee","userId":"05601282561867616863"},"user_tz":-540},"id":"C_lESWWJu8Ig","outputId":"dfbadfbd-f4c4-455d-861f-c5721c3cfc19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive/\", force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708653321587,"user":{"displayName":"Chaewon Lee","userId":"05601282561867616863"},"user_tz":-540},"id":"MZPFw_vgvAV9","outputId":"74400084-55e7-41f5-9b78-9e1275265c69"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/2024_MCL_Internship/MNIST\n"]}],"source":["cd \"/content/gdrive/MyDrive/2024_MCL_Internship/MNIST\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsmTarWZM2K3"},"outputs":[],"source":["import torch\n","from torch.utils import data\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","\n","from matplotlib import pyplot as plt\n","import os\n","from time import time"]},{"cell_type":"markdown","metadata":{"id":"zRLH4EpMNFy9"},"source":["Dataset 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJu-a0wSM_Km"},"outputs":[],"source":["class mnist_train(data.Dataset):\n","    def __init__(self):\n","        self.bytes_images = list(open(f\"dataset/train-images.idx3-ubyte\", \"rb\").read()[16:])\n","        self.bytes_labels = list(open(\"dataset/train-labels.idx1-ubyte\", \"rb\").read()[8:])\n","\n","    def __getitem__(self, idx):\n","        image = torch.Tensor(self.bytes_images[idx * 784:(idx + 1) * 784])\n","        image = torch.reshape(image, (1, 28, 28)) / 255.0\n","        label = self.bytes_labels[idx]\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.bytes_labels)\n","\n","class mnist_test(data.Dataset):\n","    def __init__(self):\n","        self.bytes_images = list(open(f\"dataset/t10k-images.idx3-ubyte\", \"rb\").read()[16:])\n","        self.bytes_labels = list(open(\"dataset/t10k-labels.idx1-ubyte\", \"rb\").read()[8:])\n","\n","    def __getitem__(self, idx):\n","        image = torch.Tensor(self.bytes_images[idx * 784:(idx + 1) * 784])\n","        image = torch.reshape(image, (1, 28, 28)) / 255.0\n","        label = self.bytes_labels[idx]\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.bytes_labels)"]},{"cell_type":"markdown","metadata":{"id":"mJktls2QzQiI"},"source":[" 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOwOhuL3zSiQ"},"outputs":[],"source":["import random\n","\n","train_dataset = mnist_train()\n","test_dataset = mnist_test()\n","\n","print(\"total length of train dataset : \", len(train_dataset))\n","print(\"total length of test dataset : \", len(test_dataset))\n","i = random.randrange(len(train_dataset))\n","image_train, label_train = train_dataset[i]\n","image_train_PIL = transforms.ToPILImage()(image_train)\n","display(image_train_PIL)\n","print(label_train)\n","print()\n","\n","i = random.randrange(len(test_dataset))\n","image_test, label_test = test_dataset[i]\n","image_test_PIL = transforms.ToPILImage()(image_test)\n","display(image_test_PIL)\n","print(label_test)"]},{"cell_type":"markdown","metadata":{"id":"Ny4PuALvNN5M"},"source":["model 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxf1wX2tNDwo"},"outputs":[],"source":["class Linear_Model(nn.Module):\n","    def __init__(self, is_BN):\n","        super(Linear_Model, self).__init__()\n","        self.flatten = nn.Flatten()\n","        if is_BN:\n","            self.linear = nn.Sequential(\n","                nn.Linear(784, 128),\n","                nn.ReLU(),\n","                nn.Linear(128, 64),\n","                nn.BatchNorm1d(64),\n","                nn.ReLU(),\n","                nn.Linear(64, 10),\n","                nn.Softmax(dim=1)\n","            )\n","        else:\n","            self.linear = nn.Sequential(\n","                nn.Linear(784, 128),\n","                nn.ReLU(),\n","                nn.Linear(128, 64),\n","                nn.ReLU(),\n","                nn.Linear(64, 10),\n","                nn.Softmax(dim=1)\n","            )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"yWsuTExFb_NU"},"source":["train 코드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nV4s8aAtX__Y"},"outputs":[],"source":["def train_model(info):\n","    if info['is_BN']:\n","        isBN = f'withBN'\n","    else:\n","        isBN = f'withoutBN'\n","\n","    print(f\"Model : {info['model']}, Batch Normalization : {isBN}\")\n","    epochs = info[\"epochs\"]\n","\n","    writer = info[\"writer\"]\n","\n","    ckpt_path = os.path.join('checkpoints', f\"{info['model']}_{isBN}\")\n","    if not os.path.exists('checkpoints'): os.mkdir('checkpoints')\n","    if not os.path.exists(ckpt_path): os.mkdir(ckpt_path)\n","\n","    train_dataset = mnist_train()\n","    test_dataset = mnist_test()\n","    train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=info[\"batch_size\"], shuffle=True,\n","                                       pin_memory=True)\n","    test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=info[\"batch_size\"], shuffle=False,\n","                                      pin_memory=True)\n","\n","    # 모델 선언, gpu loading\n","    model = Linear_Model(info[\"is_BN\"])\n","    model.cuda()\n","\n","    # Loss Function, Optimizer 선언\n","    loss_function = nn.CrossEntropyLoss().cuda()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=info[\"lr\"])\n","\n","    # 에폭별 loss, test acc 담을 list\n","    log_loss_train = []\n","    log_loss_test = []\n","    log_acc_test = []\n","\n","    # epoch 반복문, iteration, 네트워크 train, epoch별 test\n","    for epoch in range(epochs):\n","        # train 준비\n","        start_time = time()\n","        train_loss_per_epoch = 0\n","        model.train()\n","\n","        # mini batch 불러오기 반복문\n","        for iter, batch in enumerate(train_dataloader):\n","            image = batch[0].cuda()\n","            label = batch[1].cuda()\n","\n","            y = model(image) # y size : Batch x 10\n","            loss_train = loss_function(y, label)\n","\n","            optimizer.zero_grad()\n","            loss_train.backward()\n","            optimizer.step()\n","\n","            train_loss_per_epoch += loss_train.item() / len(train_dataloader)\n","\n","            # tensorboard에 step별 train loss 저장\n","            writer.add_scalar(f\"{info['model']}_{isBN}/Train_Loss\", loss_train, epoch * len(train_dataloader) + iter)\n","\n","        # 에폭별 train 결과 출력해보기\n","        print(f\"Epoch[{epoch}] Loss: {train_loss_per_epoch:.4f}\", end=\"\")\n","        log_loss_train.append(train_loss_per_epoch)\n","\n","        # test 준비\n","        model.eval()\n","        loss_test_epoch = 0\n","        total_num_accs = 0\n","\n","        # test 시에 tensor에 gradient 위한 기록 남길 필요 없음\n","        with torch.no_grad():\n","            # test에서 mini-batch 불러오기\n","            for iter, batch in enumerate(test_dataloader):\n","                image = batch[0].cuda()\n","                label = batch[1].cuda()\n","\n","                y = model(image) # size of y : Batch x 10\n","                loss_test = loss_function(y, label)\n","\n","                loss_test_epoch += loss_test.item() / len(test_dataloader)\n","\n","                y_ = torch.argmax(y, dim=1) # size of y_ : batch x 1\n","                num_accs = torch.sum(y_ == label).item()\n","                total_num_accs += num_accs / (len(test_dataloader) * info[\"batch_size\"])\n","\n","\n","        # tensorboard에 test 결과 기록 (Loss, Accuracy)\n","        writer.add_scalar(f\"{info['model']}_{isBN}/Test_Loss\", loss_test_epoch, epoch)\n","        writer.add_scalar(f\"{info['model']}_{isBN}/Test_Accuracy\", total_num_accs * 100, epoch)\n","        log_loss_test.append(loss_test_epoch)\n","        log_acc_test.append(total_num_accs * 100)\n","\n","\n","        # 네트워크 파라미터 중간 저장\n","        if (epoch + 1) % 10 == 0:\n","            torch.save({'epoch': epoch,\n","                        'model_state_dict': model.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict()}, f'{ckpt_path}/Epoch{epoch:03d}.pth')\n","\n","        time_per_epoch = time() - start_time\n","        print(\n","            f\" Test Loss: {loss_test_epoch:.4f} Accuracy Rate: {total_num_accs * 100:.2f}% time per epoch: {time_per_epoch:.2f}sec\")\n","\n","    return log_loss_train, log_loss_test, log_acc_test"]},{"cell_type":"markdown","metadata":{"id":"5jOSLcgV7leM"},"source":["Linear 네트워크 main 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNiNlA4d7sfl"},"outputs":[],"source":["if not os.path.exists('logs'): os.mkdir('logs')\n","writer = SummaryWriter('logs')\n","\n","info = {\n","    \"epochs\" : 100,\n","    \"batch_size\" : 500,\n","    \"lr\" : 0.01,\n","    \"model\" : \"Linear_Model\",\n","    \"is_BN\" : True,\n","    \"writer\" : writer\n","}\n","\n","linear_BN = train_model(info)\n","\n","info[\"is_BN\"] = False\n","linear_withoutBN = train_model(info)"]},{"cell_type":"markdown","metadata":{"id":"q87rXqcP77QP"},"source":["학습 결과를 그래프로 plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56wgTw_T77os"},"outputs":[],"source":["# --- Logs Visualization\n","# training loss\n","plt.plot(linear_BN[0], label='Linear_withBN')\n","plt.plot(linear_withoutBN[0], label='Linear_withoutBN')\n","plt.xticks(list(range(0, info[\"epochs\"], info[\"epochs\"] // 5)))\n","plt.show()\n","plt.savefig('logs/training_loss_Linear.png')\n","plt.clf()\n","\n","# test loss\n","plt.plot(linear_BN[1], label='Linear_withBN')\n","plt.plot(linear_withoutBN[1], label='Linear_withoutBN')\n","plt.xticks(list(range(0, info[\"epochs\"], info[\"epochs\"] // 5)))\n","plt.show()\n","plt.savefig('logs/test_loss_Linear.png')\n","plt.clf()\n","\n","# test accuracy\n","plt.plot(linear_BN[2], label='Linear_withBN')\n","plt.plot(linear_withoutBN[2], label='Linear_withoutBN')\n","plt.xticks(list(range(0, info[\"epochs\"], info[\"epochs\"] // 5)))\n","plt.show()\n","plt.savefig('logs/test_acc_Linear.png')\n","plt.clf()"]},{"cell_type":"markdown","metadata":{"id":"W2FtAxfocHxd"},"source":["tensorboard 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ox6hH94NcI7F"},"outputs":[],"source":["%load_ext tensorboard\n","\n","%tensorboard --logdir logs"]},{"cell_type":"markdown","metadata":{"id":"SApEWAyCMud8"},"source":["손글씨 직접 써보기 예시 - image pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2moA3bGmM0N8"},"outputs":[],"source":["from PIL import Image\n","import numpy as np\n","import torchvision.transforms as TF\n","import cv2\n","\n","img3 = np.array(Image.open(f'3.png'))\n","img5 = np.array(Image.open(f'5.png'))\n","img7 = np.array(Image.open(f'7.png'))\n","img3 = cv2.resize(img3, (28, 28), interpolation = cv2.INTER_AREA)\n","img5 = cv2.resize(img5, (28, 28), interpolation = cv2.INTER_AREA)\n","img7 = cv2.resize(img7, (28, 28), interpolation = cv2.INTER_AREA)\n","img3 = Image.fromarray(img3).convert('L')\n","img5 = Image.fromarray(img5).convert('L')\n","img7 = Image.fromarray(img7).convert('L')\n","display(img3)\n","display(img5)\n","display(img7)\n","\n","img3 = TF.ToTensor()(img3)\n","img5 = TF.ToTensor()(img5)\n","img7 = TF.ToTensor()(img7)\n","\n","img3 = img3.unsqueeze(0).cuda()\n","img5 = img5.unsqueeze(0).cuda()\n","img7 = img7.unsqueeze(0).cuda()\n","\n","model = Linear_Model(True)\n","model.cuda()\n","ckpt = torch.load(f'checkpoints/Linear_Model_withBN/Epoch099.pth')\n","model.load_state_dict(ckpt['model_state_dict'])\n","model.eval()\n","with torch.no_grad():\n","    logits = model(img3)\n","    print(torch.argmax(logits).item())\n","    print()\n","    logits = model(img5)\n","    print(torch.argmax(logits).item())\n","    print()\n","    logits = model(img7)\n","    print(torch.argmax(logits).item())"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}